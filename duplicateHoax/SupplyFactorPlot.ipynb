{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to plot retweet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_published_dataframe = pd.read_pickle(\"/data/Hoaxy/Date100k.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.shape\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path =  '/data/Hoaxy/code/Hoaxy/near-dup-detection/ndd/hoax/100k_fact_networks_updated_v2'\n",
    "file_num = 805\n",
    "file_name = 'fact_network_'+str(file_num)+'.pkl.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle((path+'/'+file_name))\n",
    "print(df.shape)\n",
    "df_after_duplicates = df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "ids = df_after_duplicates['id'].unique()\n",
    "\n",
    "date = []\n",
    "for i in ids:\n",
    "    date.append(date_published_dataframe.loc[date_published_dataframe['id'] == i,'pdate'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date)\n",
    "df_after_duplicates['canonical_url_updated'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = df_after_duplicates[['from_user_id','to_user_id','tweet_created_at']]\n",
    "dataset['tweet_date'] = dataset['tweet_created_at'].str[:10]\n",
    "df_after_duplicates['canonical_url_x'].unique()\n",
    "final_data = dataset.drop(['tweet_created_at'], axis=1)\n",
    "final_data.index = pd.DatetimeIndex(final_data.tweet_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_plot = final_data[['tweet_date']]\n",
    "data_for_plot['count'] =1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_for_plot['tweet_date'] = pd.to_datetime(data_for_plot['tweet_date'])\n",
    "# new version\n",
    "data_for_plot.groupby(pd.Grouper(key='tweet_date', freq=\"D\")).size().plot(label = 'Retweet over time')\n",
    "plt.ylabel(\"# retweets\")\n",
    "\n",
    "colors = ['r','g','c']\n",
    "for xc,c in zip(date,colors):\n",
    "    plt.axvline(x=xc,label='Published date = '+xc, c=c,linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(\"Supply_factor_\"+str(file_num)+\".pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
